{\rtf1\ansi\ansicpg1252\cocoartf2509
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 Helvetica-Bold;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww28600\viewh15200\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Top consuming queries to be tuned, reasons of the same could be \
	structural changes, \
	changes in data volume, \
	application changes\
	aged statistics\
	DB upgrades\
	DB parameter changes\
	OS & hardware changes\
\
Bad SQL will have unnecessary\
	Parse time\
	IO operations - too many data blocks against less data blocks extraction\
	CPU time\
	waits\
They are caused by bad design, poor coding, inefficient execution plan\
\
Parse - Parsing SQL, allocating private SQL area and creating execution plan\
\
Good Schema Design - \
		Data type usage with sufficient length - varchar2 is variable type, so it allocates only as much memory needed\
		parent and child (primary and foreign) table keys of same data type else CPU usage will be high as it has to do data conversion and join\
		create appropriate check constraints\
		normalisation rules to avoid redundancy issues\
		use the appropriate tables either - heap organised tables, index organised tables and hash clustered tables\
\
When query comes - first checks in results cache, \
				if no then goes to shared SQL area for similar execution plan else will create, \
				then goes to buffer cache if data needed available else will go to disk\
				disk blocks are to be picked up\
				if data to be picked is single index works well instead if range of rows, then entire table to be read and filtered\
This is handled by partitioning - dividing table into smaller partitions based on a key field like hire date in hire table - creating partition for every year\
This way if our query needs data from 1 partition in a 100 partitions table, then it will not go through 100 partitions, but directly will go to that partition - this will cause 100x performance improvement\
Same way indexes also can be partitioned as indexes also grow \
\

\f1\b\fs28 \ul How SQL Statement is processed?
\f0\b0\fs24 \ulnone \
First syntax check\
Then semantics check for the necessary tables and columns if they are present from data dictionary cache\
Privilege Check also from data dictionary cache\
Create private SQL area in user PGA, results are stored here for a while\
Execution plan is checked in shared SQL area for similar queries If found then it becomes soft parse or library cache hit\
If you don\'92t need to create execution plan and get it from shared SQL area it becomes soft parse else its hard parse\
In tuning maximum focus is to execute from shared SQL area to improve performance significantly\
The code is not directly stored in SQL area instead hash value of query is stored as key for execution plan in library cache\
When query is run, this hash value is searched for execution plan in SQL area. Queries have to be exactly same for the key to match\
If no hash value is found then execution plan has to be created which is called hard parse or library cache miss\
For hard parse - Allocate shared SQL area, if its full first delete aged one > Optimisation > Optimizer returns best execution plan after calculating several execution plans\
Optimizer value is 1 second as generally best execution plan is returned within a second, if its higher there will be lot of load in CPU\
Once execution plan done > Row source generation process: Each step like getting data, joining, sorting them >> Using the steps statement is executed \
When same query is executed instead of hard parsing or searching in shared SQL area, it goes to library cache and executes the plan\
Once query is run execution plan is stored in library cache, row id of execution plan is stored in shared SQL area\
When you run the same statement, it takes row id from shared SQL area and goes to library cache & executes the plan\
Not all queries execution plan hash is stored in cache, 50 is the limit\
Parsing is also an expensive operation , we can use result caching\
\
\
\
\
\
\
\
\
	\
		\
		\
	}